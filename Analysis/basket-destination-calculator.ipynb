{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basket Destination Calculator\n",
    "\n",
    "The purpose of this script is to construct a market basket of destinations relevant to people who travel in Seattle. The basket may include collections of trips to nearby points of interest and activity centers that are specific to each origin, and a collection of trips to citywide destinations that are the same for all starting points. \n",
    "\n",
    "Instead of using a complicated, multi-step transportation land use model to create the basket of destinations, the Basket of Destinations Calculator uses a low-cost, repeatable and scalable algorithm that creates a list of actual destinations for every origin. The universe of possible destinations is a combination of a curated list of citywide locations that each block group will have access to (GoogleMatrix_Places_Citywide.csv) and an algorithm-generated list of local destinations pulled from the google places api. The local list (GoogleMatrix_Places.csv) is created by google-place-search.ipynb. This mechanics of this algorithm can be visualized here:\n",
    "\n",
    "https://public.tableau.com/views/Basket_of_Destinations/Dashboard?:embed=y&:display_count=yes\n",
    "\n",
    "This script accesses the Google Map Distance Matrix API to rank each possible origin-destination by their driving distance. The basket definition is created by using parameters to filter each class of destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "try:\n",
    "    from urllib.request import Request, urlopen  # Python 3\n",
    "except:\n",
    "    from urllib2 import Request, urlopen  # Python 2\n",
    "    \n",
    "import string\n",
    "valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_Key = open(\".\\Variables\\google_distance_query.txt\", 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine google places with citywide places for a full list of destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Google places data with citywide places. The citywide file contain urban villages, destination parks, and \n",
    "# citywide points.\n",
    "df_Places_Google = pd.read_csv('V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places.csv')\n",
    "df_Places_Citywide = pd.read_csv('V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places_Citywide.csv')\n",
    "df_Places_Full = pd.concat([df_Places_Google,df_Places_Citywide])\n",
    "df_Places_Full.to_csv(\"V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places_Full.csv\", mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance (and travel time) to each destination \n",
    "def distanceToBasket(origin, originLat, originLong):\n",
    "    \n",
    "    dfDestinations = pd.read_csv('V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places_Full.csv') \n",
    "\n",
    "    minLat = originLat - .8\n",
    "    maxLat = originLat + .8\n",
    "    minLng = originLong - .8\n",
    "    maxLng = originLong + .8\n",
    "    \n",
    "    # filter general destinations that are approximately less than 5-6 miles away \n",
    "    dfDestinations = dfDestinations[(dfDestinations['class'] == \"citywide\") | \n",
    "                                    (dfDestinations['class'] == \"urban village\") | \n",
    "                                    (\n",
    "                                    (dfDestinations['lat'] > minLat) & (dfDestinations['lat'] < maxLat) &\n",
    "                                    (dfDestinations['lng'] > minLng) & (dfDestinations['lng'] < maxLng)\n",
    "                                    )\n",
    "                                     ]\n",
    "                                     \n",
    "    Distance = []\n",
    "    \n",
    "    for index, row in dfDestinations.iterrows():\n",
    "\n",
    "        # Build the Origin and Destination strings\n",
    "        Origin = str(originLat) + \",\" + str(originLong)\n",
    "        Destination = str(row[\"lat\"]) + \",\" + str(row[\"lng\"])\n",
    "        URL = \"https://maps.googleapis.com/maps/api/distancematrix/json?units=imperial&mode=driving&origins=\" + Origin + \\\n",
    "                     \"&destinations=\" + Destination + \"&key=\" + API_Key\n",
    "        #print (URL)\n",
    "        q = Request(URL)\n",
    "        a = urlopen(q).read()\n",
    "        data = json.loads(a)\n",
    "\n",
    "        if 'errorZ' in data:\n",
    "            print (data[\"error\"])\n",
    "        \n",
    "        df = json_normalize(data['rows'][0]['elements'])  \n",
    "        df['distance.value'] = df['distance.value']/1609\n",
    "        Distance.append(df['distance.value'].tolist()[0])    \n",
    "        \n",
    "     #   print (df)  \n",
    "    dfDestinations['distance'] = Distance\n",
    "    dfDestinations['origin'] = origin\n",
    "    dfDestinations['pair'] = dfDestinations['origin'].astype(str)  + \"-\" + dfDestinations['place_id'].astype(str)\n",
    "    \n",
    "    # Sort and rank by class\n",
    "    dfDestinations['rank'] = dfDestinations.groupby(['class'])['distance'].rank(ascending=True)\n",
    "    \n",
    "    \n",
    "    # Export to csv\n",
    "    if os.path.exists(\"V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places_Dist.csv\"):\n",
    "        dfDestinations.to_csv(\"V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places_Dist.csv\", mode='a', header=False, index=False)\n",
    "    else:\n",
    "        dfDestinations.to_csv(\"V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places_Dist.csv\", mode='w', header=True, index=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call google distance matrix API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of origins and call the distance to basket function for each origin\n",
    "dfOrigins = pd.read_csv('V:\\Asset Management Program\\Data Science\\Geographies\\\\SeattleCensusBlocksandNeighborhoodCorrelationFile.csv')\n",
    "\n",
    "dfOrigins = dfOrigins[\n",
    "                    (dfOrigins['BLOCKGROUP'] == 530330062001) |\n",
    "                      (dfOrigins['BLOCKGROUP'] == 530330030003) |\n",
    "                      (dfOrigins['BLOCKGROUP'] == 530330068002) |\n",
    "                    (dfOrigins['BLOCKGROUP'] == 530330107012) |\n",
    "                      (dfOrigins['BLOCKGROUP'] == 530330077003)\n",
    "]\n",
    "\n",
    "for index, row in dfOrigins.iterrows():\n",
    "    print (row['BLOCKGROUP'])\n",
    "    distanceToBasket(row['BLOCKGROUP'],row['CT_LON'],row['CT_LAT'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the universe of baskets to match parameter limits. This will reduce the size of the table to make it easier\n",
    "# for analysis and geocoding \n",
    "\n",
    "def distilleBasketPrelim():\n",
    "\n",
    "    df_destinations = pd.read_csv('V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places_Dist.csv') \n",
    "    \n",
    "    # filter destination based on rank (distance from destination)\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"urban village\") | (df_destinations['rank'] <= 5)]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"citywide\") | (df_destinations['rank'] <= 20)]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"destination park\") | (df_destinations['rank'] <= 5)]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"supermarket\") | (df_destinations['rank'] <= 5)]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"library\") | (df_destinations['rank'] <= 5)]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"hospital\") | (df_destinations['rank'] <= 5)]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"pharmacy\") | (df_destinations['rank'] <= 5)]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"post_office\") | (df_destinations['rank'] <= 5)]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"school\") | (df_destinations['rank'] <= 5)]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"cafe\") | (df_destinations['rank'] <= 5)]\n",
    "\n",
    "    df_destinations.to_csv(\"V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places_Dist.csv\", mode='w', header=True, index=False)\n",
    "    \n",
    "distilleBasketPrelim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune and Evaluate Model\n",
    "We will evaluate the model by comparing the 'proximity ratio' from the results with the ratio from the PSRC survey for each block group. We will look at all possible parameter calculations and identify the ones with the lowest scores.\n",
    "\n",
    "We can compare results with the Puget Sound Regional Household Travel Survey. However, keep in mind that survey techniques incorporate behavior biases, such as those based on income, job status, etc. But our universal basket of destinations is based on opportunity, for which we do not want to start with different basket for different people. This does not preclude the use of weighting coefficients that could tune baskets for different income levels or types of households. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the basket for each blockgroup, calculate the proximity ratio, and compare it with sample results from\n",
    "# the PSRC survey\n",
    "\n",
    "def distilleBasketTest(testArray):\n",
    "    \n",
    "    global df_sample \n",
    "    global df_destinations\n",
    "    \n",
    "    # filter to match basket parameters based on rank (distance from destination)\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"urban village\") | (df_destinations['rank'] <= testArray[0])]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"citywide\") | (df_destinations['rank'] <= testArray[1])]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"destination park\") | (df_destinations['rank'] <= testArray[2])]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"supermarket\") | (df_destinations['rank'] <= testArray[3])]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"library\") | (df_destinations['rank'] <= testArray[4])]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"hospital\") | (df_destinations['rank'] <= testArray[5])]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"pharmacy\") | (df_destinations['rank'] <= testArray[6])]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"post_office\") | (df_destinations['rank'] <= testArray[7])]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"school\") | (df_destinations['rank'] <= testArray[8])]\n",
    "    df_destinations = df_destinations[(df_destinations['class'] != \"cafe\") | (df_destinations['rank'] <= testArray[9])]\n",
    "    \n",
    "    # aggregate block group trips\n",
    "    # proximity ration = trips under 2 miles vs trips between 2 and 10 miles\n",
    "    df_destinations['dist_under_2'] = np.where(df_destinations['distance'] < 2.0,1,0)\n",
    "    df_destinations['dist_2_to_10'] = np.where((df_destinations['distance']>=2) & (df_destinations['distance']<10.0),1,0)\n",
    "    df_blockgroup = df_destinations.groupby(['origin'], as_index=False).agg({'dist_under_2':sum,'dist_2_to_10':sum})\n",
    "    df_blockgroup['proximity_ratio_test'] = df_blockgroup['dist_under_2']/df_blockgroup['dist_2_to_10']\n",
    " \n",
    "    print (df_blockgroup)\n",
    "    # merge with evaluation file\n",
    "    df_merged = pd.merge(left=df_blockgroup, right=df_sample, how='left', left_on='origin', right_on='bg_origin')\n",
    "    df_merged = df_merged.dropna()\n",
    "    \n",
    "    # evaluate results for this test array\n",
    "    target = df_merged['proximity_ratio']\n",
    "    predictions = df_merged['proximity_ratio_test']\n",
    "    mse = mean_squared_error(target, predictions)\n",
    "\n",
    "    return (mse)\n",
    "\n",
    "df_sample = pd.read_csv('V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\Proximity_Ratio.csv') \n",
    "df_destinations = pd.read_csv('V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places_Dist.csv') \n",
    "\n",
    "testArray = [2,11,3,2,2,2,1,0,1,2]\n",
    "distilleBasketTest(testArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Brute force function to evaluate all combinations. There are 200,000 possible combinations.\n",
    "\n",
    "import itertools\n",
    "\n",
    "df_sample = pd.read_csv('V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\Proximity_Ratio.csv') \n",
    "df_destinations = pd.read_csv('V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places_Dist.csv') \n",
    "\n",
    "df_basketCombinations = pd.DataFrame()\n",
    "\n",
    "\n",
    "sizeLimit = 25\n",
    "\n",
    "# Define parameter domain\n",
    "AA = [0,1,2,3,4] # urban village\n",
    "BB = [8,9,10,11,12,13] # citywide destination\n",
    "A = [0,1,2,3] # destination park\n",
    "B = [0,1,2,3] # supermarket\n",
    "C = [0,1,2,3] # library\n",
    "D = [0,1,2,3] # hospital\n",
    "E = [0,1,2,3] # pharmacy\n",
    "F = [0,1,2,3] # post office\n",
    "G = [0,1,2,3] # school\n",
    "H = [0,1,2,3] # cafe\n",
    "\n",
    "countCombinations = 0\n",
    "Score = []\n",
    "Parameters = []\n",
    "\n",
    "for x in itertools.product(AA,BB,A,B,C,D,E,F,G,H):\n",
    "    \n",
    "    countVariables = 0\n",
    "\n",
    "    for item in x:\n",
    "        countVariables += item\n",
    "    \n",
    "    if countVariables == sizeLimit: # valid combination\n",
    "       # Parameters.append(x)\n",
    "       # Score.append(distilleBasketTest(x))\n",
    "        countCombinations += 1\n",
    "\n",
    "print (\"Combinations: \" + str(countCombinations))\n",
    "#df_basketCombinations['score'] = Score\n",
    "#df_basketCombinations['parameters'] = Parameters\n",
    "\n",
    "#df_basketCombinations.to_csv(\"V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\Basket_scores.csv\", mode='w', header=True, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
