{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Place Search API Scrape\n",
    "\n",
    "The purpose of this script is to generate a list of destinations in and near the city from which to choose the basket of destinations for each blockgroup. This should be a scalable, repeatable process that can be refreshed from time to time as the amenities in the city change.\n",
    "\n",
    "This script accesses the Google Map Places API. Note there are usage limits terms of service, such as displaying a Google map at https://developers.google.com/maps/documentation/distance-matrix/usage-limits\n",
    "https://developers.google.com/places/web-service/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from urllib.request import Request, urlopen  # Python 3\n",
    "except:\n",
    "    from urllib2 import Request, urlopen  # Python 2\n",
    "    \n",
    "import string\n",
    "valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_Key = open(\".\\Variables\\google_place_query.txt\", 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchPlaces(seachtype,location,pagetoken):\n",
    "\n",
    "    # save add page token parameter if not a new search\n",
    "    if pagetoken == \"none\":\n",
    "        URL = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json?&location=\" + location + \\\n",
    "                     \"&rankby=distance&types=\" + searchtype + \"&key=\" + API_Key\n",
    "    else:\n",
    "        URL = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json?&key=\" + API_Key + \"&pagetoken=\" + pagetoken\n",
    "    \n",
    "    print (URL)\n",
    "    q = Request(URL)\n",
    "    a = urlopen(q).read()\n",
    "    data = json.loads(a)\n",
    "    \n",
    "    dfPlaces = json_normalize(data,['results'])\n",
    "    print (dfPlaces)\n",
    "    dfPlaces['lat'] = dfPlaces['geometry'].apply(lambda x: x['location']['lat'])\n",
    "    dfPlaces['lng'] = dfPlaces['geometry'].apply(lambda x: x['location']['lng'])\n",
    "    dfPlaces['city'] = dfPlaces['vicinity'].apply(lambda x: ''.join(x.split(', ')[-1:]))\n",
    "    dfPlaces['address'] = dfPlaces['vicinity'].apply(lambda x: ''.join(x.split(', ')[-2:-1]))\n",
    "    \n",
    "    dfOut = dfPlaces[['name','address','city','lat','lng','place_id','types']]\n",
    "    \n",
    "    # Add ratings if they exist in the query\n",
    "    if 'rating' in dfPlaces.columns:\n",
    "        dfOut['rating'] = dfPlaces['rating']\n",
    "    else:\n",
    "        dfOut['rating'] = \"\"\n",
    "        \n",
    "    dfOut['class'] = seachtype\n",
    "    #dfOut['blockgroup'] = blockgroup\n",
    "    \n",
    "    # save a new csv if first search, append if pagetoken\n",
    "    if os.path.exists(\"V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places.csv\"):\n",
    "        dfOut.to_csv(\"V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places.csv\", mode='a', header=False, index=False)\n",
    "    else:\n",
    "        dfOut.to_csv(\"V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places.csv\", mode='w', header=True, index=False)\n",
    "\n",
    "    # Keep searching if there are more records, there is a 3 page limit\n",
    "    if 'next_page_token' in data.keys():\n",
    "        time.sleep(2)\n",
    "        pagetoken = data['next_page_token']\n",
    "        searchPlaces(searchtype,location,pagetoken)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the google search algorithm returns places in proximity to the search location, we are\n",
    "# searching at every urban village. This should cover the entire city with redundant results so \n",
    "# we are filtering out duplicates. We are also looking at the returned values and filtering out \n",
    "# results to get a clean, repeatable list.\n",
    "\n",
    "types = ['supermarket','library','hospital','pharmacy','post_office','school','cafe','store']\n",
    "\n",
    "df_origins = pd.read_csv('V:\\\\Asset Management Program\\\\Data Science\\\\Geographies\\\\UV_Origins.csv')\n",
    "#df_origins = df_origins[df_origins['uv_origin'] == 'West Seattle Junction']\n",
    "\n",
    "for index, row in df_origins.iterrows():\n",
    "    \n",
    "    location = str(row['origin_lat']) + \",\" + str(row['origin_lng'])\n",
    "    \n",
    "    for searchtype in types:\n",
    "        pagetoken = \"none\"        \n",
    "        #searchPlaces(row['BLOCKGROUP'],searchtype,location,pagetoken)\n",
    "        searchPlaces(searchtype,location,pagetoken)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean and filter search results. Unfortunately a necessary step\n",
    "\n",
    "dfPlaces = pd.read_csv('V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places.csv')\n",
    "\n",
    "#dfPlaces = dfPlaces[dfPlaces['city'] == \"Seattle\"]\n",
    "\n",
    "# drop all supermarkets with no ratings\n",
    "dfPlaces = dfPlaces[(dfPlaces['class'] != \"supermarket\") | (dfPlaces['rating'] > 0)]\n",
    "\n",
    "# drop all libraries that do not contain \"Seattle Public Library\"\n",
    "dfPlaces = dfPlaces[(dfPlaces['class'] != \"library\") | (dfPlaces['name'].str.contains(\"Seattle Public Library\"))]\n",
    "\n",
    "# drop pharmacies with ratings Nan or less than two\n",
    "dfPlaces = dfPlaces[(dfPlaces['class'] != \"pharmacy\") | (dfPlaces['rating'] > 2)]\n",
    "\n",
    "# drop hospitals with ratings Nan or less than three\n",
    "dfPlaces = dfPlaces[(dfPlaces['class'] != \"hospital\") | (dfPlaces['rating'] > 3)]\n",
    "\n",
    "# drop post offices with ratings Nan\n",
    "dfPlaces = dfPlaces[(dfPlaces['class'] != \"post_office\") | (dfPlaces['rating'] > 0 )]\n",
    "\n",
    "# drop all schools that do not contain \"Elementary, High, Middle\"\n",
    "dfPlaces = dfPlaces[(dfPlaces['class'] != \"school\") | ((dfPlaces['name'].str.contains(\"High\")) | \n",
    "                                                        (dfPlaces['name'].str.contains(\"Middle\")) |\n",
    "                                                        (dfPlaces['name'].str.contains(\"Elementary\")))]\n",
    "\n",
    "# drop all stores that do not contain \"supermarket\", set them to class supermarket\n",
    "dfPlaces = dfPlaces[(dfPlaces['class'] != \"store\") | (dfPlaces['types'].str.contains(\"supermarket\"))]\n",
    "dfPlaces['class'].loc[dfPlaces['class'] == 'store'] = 'supermarket'\n",
    "\n",
    "# drop all supermarkets that contain \"furniture_store\" \n",
    "dfPlaces = dfPlaces[(dfPlaces['class'] != \"supermarket\") | (~dfPlaces['types'].str.contains(\"furniture_store\"))]\n",
    "\n",
    "# drop duplicate place IDs\n",
    "dfPlaces = dfPlaces.drop_duplicates(subset=['place_id'], keep='first', inplace=False)\n",
    "\n",
    "dfPlaces = dfPlaces.reset_index(drop=True)\n",
    "\n",
    "print (dfPlaces)\n",
    "dfPlaces.to_csv(\"V:\\\\Asset Management Program\\\\Data Science\\\\Data\\\\GoogleMatrix_Places.csv\", mode='w', header=True, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
